# Homework 02
setwd("~/WORKING_DIRECTORIES/biostat.696/homework02")
library(readr)
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)
library(akima)
library(fields)
library(dplyr)
library(broom)
library(gstat)
library(geoR)

data <- read_table2("BatonRouge.txt")
colnames(data) <- c("logSP", "AreaL", "AreaO", "Age",
                    "Bed", "Bath", "HBath", "Lat",
                    "Lon", "East", "North")
data$EastKM <- data$East/1000
data$NorthKM <- data$North/1000

# Plot the sampled sites with the corresponding observed 
# log-selling prices
ggplot() +
  geom_point(data = data,
             aes(x=EastKM, y = NorthKM, color = logSP)) +
  ggtitle("Log Selling Price of Homes in Baton Rouge, LA") +
  theme(plot.title = element_text(hjust = 0.5)) +
  xlab("Easting (km)") +
  ylab("Northing (km)") +
  scale_color_gradient(name = "Log Selling Price")

# Fit an ordinary least squares regression
data50 <- data[1:50,]
mod01 <- lm(data = data50,
            logSP ~ AreaL + Age + AreaO + Bath)
summary(mod01)
data50$res <- resid(mod01)

# Obtain empirical semi-variogram of the residuals
emp_var <- variogram(res~1, locations =~ East+North, data50, width = 500, cutoff = 5000)
emp_var
plot(emp_var,col="black",type="p",pch=20, main = "Empirical Variogram")

# Fit exponential semi-variogram
exp_var <- fit.variogram(emp_var,vgm(psill=0.02,"Exp",range=120,nugget=0.005),fit.method=2)
exp_var
plot(emp_var, exp_var, main = "Exponential Semi-Variogram")

sigma2.exp <- exp_var$psill[2]
phi.exp <- exp_var$range[2]
tau2.exp <- exp_var$psill[1]

data.geo <- as.geodata(data50[,c(1,12,13)],coords.col=c(2,3),data.col=1)

reml.exp <- likfit(data.geo, trend = ~data50$AreaL+data50$AreaO+data50$Age+data50$Bath, 
                         ini=c(sigma2.exp, phi.exp), nugget=tau2.exp, fix.nug = FALSE, lik.met="REML")
reml.exp
sigma2.reml <- reml.exp$sigmasq
phi.reml <- reml.exp$phi
tau2.reml <- reml.exp$tausq

data20 <- data[c(52:71),]

hw.control <- krige.control(type.krige="ok",trend.d="1st",trend.l="1st",cov.model = "exponential",
                               cov.pars=c(sigma2.reml,phi.reml),nugget=tau2.reml)

loc.hw <- matrix(c(data20$EastKM,data20$NorthKM),nrow=20,ncol=2)
hw.pred <- krige.conv(data.geo,locations=loc.hw,krige=hw.control)
hw.pred$predict

# RMSE
sqrt(sum((hw.pred$predict-data20$logSP)^2)/20)

# MASE
sum((hw.pred$predict-data20$logSP)^2)/20

# Average of Prediction Variances
sum(hw.pred$krige.var)/20

# Confidence Interval Limits
lower <- hw.pred$predict - 1.645*sqrt(hw.pred$krige.var)
upper <- hw.pred$predict + 1.645*sqrt(hw.pred$krige.var)

contained <- 1*(data20$logSP >= lower)&(data20$logSP <= upper)


library(spBayes)
#
coords <- as.matrix(cbind(data50$EastKM, data50$NorthKM),nrow=length(data50$EastKM),ncol=2)
beta.ini <- rep(10.2816,0.0005,0,-0.0057,0.0978)
sigma2.ini <- sigma2.reml
tau2.ini <- tau2.reml + 0.0001
phi.ini <- 1/phi.reml

# This fits the model
model.1 <- spLM(data50$logSP~data50$AreaL+data50$AreaO+data50$Age+data50$Bath, 
                coords=coords,starting=list("phi"=phi.ini,"sigma.sq"=sigma2.ini, "tau.sq"=tau2.ini,"beta"=beta.ini),
                tuning=list("phi"=0.001, "sigma.sq"=0.75, "tau.sq"=0.01),
                priors=list("phi.Unif"=c(0.0001, .1), "sigma.sq.IG"=c(2, 0.06),
                            "tau.sq.IG"=c(2, 0.001),"beta.Flat"), cov.model="exponential",
                n.samples=50000, verbose=TRUE, n.report=100)

# To see the output generated by the function spLM, we can use
names(model.1)
model.1$p.theta.samples[1:5,]

# This produces traces plots and plots of the posterior marginal distribution of the covariance parameters
par(mai=rep(0.4,4))
plot(model.1$p.theta.samples[,1:3])

n.samples <- 50000
burn.in <- 0.5*n.samples
model.1.other.pars <- spRecover(model.1, start=burn.in, verbose=FALSE)

# This produces traces plots and plots of the posterior marginal distribution of the beta coefficients
dim(model.1.other.pars$p.beta.recover.samples)

par(mai=rep(0.4,4),mfrow=c(2,2))
plot(model.1.other.pars$p.beta.recover.samples[,1:4])

par(mai=rep(0.4,4))
plot(model.1.other.pars$p.beta.recover.samples[,5])

par(mai=rep(0.4,4),mfrow=c(2,2))
plot(model.1.other.pars$p.theta.samples[,1:3])

# To obtain estimates and 95% credible of the covariance parameters
round(summary(model.1.other.pars$p.theta.samples)$quantiles[,c(1,3,5)],4)
round(summary(model.1.other.pars$p.theta.samples)$statistics[,c(1,2)],4)

# To obtain estimates and 95% credible of the beta coefficients
round(summary(model.1.other.pars$p.beta.recover.samples)$quantiles[,c(1,3,5)],4)
round(summary(model.1.other.pars$p.beta.recover.samples)$statistics[,c(1,2)],4)

# Making predictions (g)
data20.predcov <- matrix(cbind(rep(1,nrow(data20)),data20$AreaL,data20$AreaO,data20$Age,data20$Bath),nrow=nrow(data20),ncol=5)
pred.coords <- cbind(data20$EastKM, data20$NorthKM)
pred <- spPredict(model.1, pred.coords=pred.coords, pred.covars=data20.predcov, start=burn.in, thin=2)
names(pred)

dim(pred$p.y.predictive.samples)

## Here we compute the posterior mean of the predictions. 
post.pred.mean <- rowMeans(pred$p.y.predictive.samples)
post.pred.mean[1:20]

## Here we compute the 95% posterior predictive intervals at the 237 sites
post.pred.95ci <- apply(pred$p.y.predictive.samples,1,quantile,c(0.05,0.95))
post.pred.95ci[,1:20]

contained.pred <- 1*(data20$logSP >= post.pred.95ci[1,])&(data20$logSP <= post.pred.95ci[2,])


# Problem 2
nyleuk <- read_table2("NY_Leukemia.txt")
colnames(nyleuk) <- c("FIPS","easting","northing","pop","cases","homeowners","over65","Avg.inv.dist.TCEs","Inv.dist.nearest.TCE")

# Plot
ggplot() +
  geom_point(data = nyleuk,
             aes(x=easting, y = northing, color = cases, size = pop)) +
  ggtitle("Leukemia Cases in NY") +
  theme(plot.title = element_text(hjust = 0.5)) +
  xlab("Easting (km)") +
  ylab("Northing (km)") +
  scale_color_gradient(name = "Number of Cases")